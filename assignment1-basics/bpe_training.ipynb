{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "345110fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex \n",
    "text = '''Once'''\n",
    "PAT = r\"\"\"<\\|endoftext\\|>|\\s+(?=<\\|endoftext\\|>)|'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "code = text.encode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdf6716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import BinaryIO\n",
    "\n",
    "\n",
    "def find_chunk_boundaries(\n",
    "    file: BinaryIO,\n",
    "    desired_num_chunks: int,\n",
    "    split_special_token: bytes,\n",
    ") -> list[int]:\n",
    "    \"\"\"\n",
    "    Chunk the file into parts that can be counted independently.\n",
    "    May return fewer chunks if the boundaries end up overlapping.\n",
    "    \"\"\"\n",
    "    assert isinstance(split_special_token, bytes), \"Must represent special token as a bytestring\"\n",
    "\n",
    "    # Get total file size in bytes\n",
    "    file.seek(0, os.SEEK_END)\n",
    "    file_size = file.tell()\n",
    "    file.seek(0)\n",
    "\n",
    "    chunk_size = file_size // desired_num_chunks\n",
    "\n",
    "    # Initial guesses for chunk boundary locations, uniformly spaced\n",
    "    # Chunks start on previous index, don't include last index\n",
    "    chunk_boundaries = [i * chunk_size for i in range(desired_num_chunks + 1)]\n",
    "    chunk_boundaries[-1] = file_size\n",
    "\n",
    "    mini_chunk_size = 4096  # Read ahead by 4k bytes at a time\n",
    "    \n",
    "    for bi in range(1, len(chunk_boundaries) - 1):\n",
    "        initial_position = chunk_boundaries[bi]\n",
    "        file.seek(initial_position)  # Start at boundary guess\n",
    "        while True:\n",
    "            \n",
    "            mini_chunk = file.read(mini_chunk_size)  # Read a mini chunk\n",
    "            # If EOF, this boundary should be at the end of the file\n",
    "            if mini_chunk == b\"\":\n",
    "                chunk_boundaries[bi] = file_size\n",
    "                break\n",
    "\n",
    "            # Find the special token in the mini chunk\n",
    "            found_at = mini_chunk.find(split_special_token)\n",
    "\n",
    "            if found_at != -1:\n",
    "                chunk_boundaries[bi] = initial_position + found_at\n",
    "                break\n",
    "            initial_position += mini_chunk_size\n",
    "\n",
    "    # Make sure all boundaries are unique, but might be fewer than desired_num_chunks\n",
    "    return sorted(set(chunk_boundaries))\n",
    "\n",
    "with open(\"tests/fixtures/tinystories_sample.txt\", \"rb\") as f:\n",
    "    num_processes = 2\n",
    "    boundaries = find_chunk_boundaries(f, num_processes, b\"<|endoftext|>\")\n",
    "\n",
    "    # The following is a serial implementation, but you can parallelize this\n",
    "    # by sending each start/end pair to a set of processes.\n",
    "    for start, end in zip(boundaries[:-1], boundaries[1:]):\n",
    "        f.seek(start)\n",
    "        chunk = f.read(end - start).decode(\"utf-8\", errors=\"ignore\")\n",
    "        \n",
    "        \n",
    "                # if n != 0:\n",
    "                #     prior = (token[n-1],token[n])\n",
    "                #     counter_buffer[prior] -= 1\n",
    "                #     new_pair = (token[n-1],merged_pair)\n",
    "                #     pair_trace[prior].remove(idx)\n",
    "                    \n",
    "                #     count = counter_buffer.get(new_pair,0) + 1\n",
    "                #     counter_buffer[new_pair] = count\n",
    "                #     new_trace = pair_trace.setdefault(new_pair, [])\n",
    "                #     new_trace.append(idx)\n",
    "                    \n",
    "                # if n != length - 2:\n",
    "                #     post = (token[n+1],token[n+2])\n",
    "                #     counter_buffer[post] -= 1\n",
    "                #     new_pair = (merged_pair,token[n+2])\n",
    "                #     count = counter_buffer.get(new_pair,0) + 1\n",
    "                #     counter_buffer[new_pair] = count\n",
    "                #     pair_trace[post].remove(idx)\n",
    "                #     new_trace = pair_trace.setdefault(new_pair, [])\n",
    "                #     new_trace.append(idx)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7f20b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union, Tuple, OrderedDict,Dict\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "def get_token_pair(token:list)->List[Tuple]:\n",
    "    \"\"\"\n",
    "    return pairs of given token\n",
    "    token: [\"12\",\"46\",\"22\"]\n",
    "    output: [(\"12\",\"46\"),(\"46\",\"22\")]\n",
    "    \"\"\"\n",
    "    return list(zip(token[:-1],token[1:]))\n",
    "\n",
    "\n",
    "def finalize_counter_buffer(counter_buffer,merged_pair,pair_trace,single_token_buffer):\n",
    "    \n",
    "    trace = set(pair_trace[merged_pair])\n",
    "    a,b = merged_pair\n",
    "    \n",
    "    for idx in trace:\n",
    "        token = single_token_buffer[idx]\n",
    "        length = len(token)\n",
    "        new_token = []\n",
    "        n = 0\n",
    "        prior_token_is_merged_token = False\n",
    "        while n < length - 1:\n",
    "            if token[n] == a and token[n+1] == b:\n",
    "                \n",
    "                new_token.append(merged_pair)\n",
    "                # 修改计数 与 路径 \n",
    "                if not prior_token_is_merged_token:\n",
    "                    if n != 0:\n",
    "                        prior = (token[n-1],token[n])\n",
    "                        counter_buffer[prior] -= 1\n",
    "                        new_pair = (token[n-1],merged_pair)\n",
    "                        pair_trace[prior].remove(idx)\n",
    "                        \n",
    "                        count = counter_buffer.get(new_pair,0) + 1\n",
    "                        counter_buffer[new_pair] = count\n",
    "                        new_trace = pair_trace.setdefault(new_pair, [])\n",
    "                        new_trace.append(idx)\n",
    "                    \n",
    "                if n != length - 2:\n",
    "                    post = (token[n+1],token[n+2])\n",
    "                    counter_buffer[post] -= 1\n",
    "                    new_pair = (merged_pair,token[n+2])\n",
    "                    count = counter_buffer.get(new_pair,0) + 1\n",
    "                    counter_buffer[new_pair] = count\n",
    "                    pair_trace[post].remove(idx)\n",
    "                    new_trace = pair_trace.setdefault(new_pair, [])\n",
    "                    new_trace.append(idx)\n",
    "                n += 1 \n",
    "                prior_token_is_merged_token = True\n",
    "            else:\n",
    "                new_token.append(token[n])\n",
    "                prior_token_is_merged_token = False\n",
    "            n += 1\n",
    "        single_token_buffer[idx] = new_token\n",
    "    \n",
    "    counter_buffer[merged_pair] = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BPE_trainier():\n",
    "    def __init__(self, PAT = None):\n",
    "        if PAT == None:\n",
    "            self.PAT = r\"\"\"<\\|endoftext\\|>|\\s+(?=<\\|endoftext\\|>)|'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "        else:\n",
    "            self.PAT = PAT\n",
    "        \n",
    "\n",
    "\n",
    "    def train(self, file_path, vocab_size ,special_tokens = [\"<|endoftext|>\"]):\n",
    "        \n",
    "        merge = []\n",
    "        start_time = time.time()\n",
    "        # 读取并切分tokens\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = f.read()\n",
    "        tokens:List[str] = regex.findall(self.PAT, data, regex.UNICODE)\n",
    "        print(\"读取数据时间:\", time.time()-start_time)\n",
    "        start_time = time.time()\n",
    "        # 初始化vocab\n",
    "        # token_buffer:List[List[Tuple[int]]] = [] # 用来存储pair\n",
    "        single_token_buffer:List[List[int]] = []\n",
    "        \n",
    "        counter_buffer:Dict[Tuple,int] = {} # pair的数量们\n",
    "\n",
    "        pair_trace:Dict[List[int]] = {} # 记录某一个pair都在哪些token中出现过\n",
    "        \n",
    "        length = len(tokens)\n",
    "        n = 0\n",
    "        while n < length:\n",
    "            token = tokens[n]\n",
    "            \n",
    "        \n",
    "            token = list(token.encode(\"utf-8\"))\n",
    "            single_token_buffer.append(token) #得到单bytes的列表. 之后用来统计数量\n",
    "            if len(token) >= 2:\n",
    "                token_pair = get_token_pair(token)\n",
    "                # token_buffer.append(token_pair) \n",
    "                for pair in token_pair:\n",
    "                    tmp_count = counter_buffer.get(pair,0) + 1\n",
    "                    counter_buffer[pair] = tmp_count\n",
    "                    trace = pair_trace.setdefault(pair, [])\n",
    "                    trace.append(n)\n",
    "            n += 1\n",
    "        \n",
    "        all_bytes = itertools.chain.from_iterable(single_token_buffer)\n",
    "        \n",
    "        counter = Counter(all_bytes)\n",
    "        \n",
    "        vocab = {value:key for (key,value) in enumerate(counter.keys())}\n",
    "        vocab_count = len(vocab)\n",
    "        for special_token in special_tokens:\n",
    "            vocab[special_token] = vocab_count + 1\n",
    "            vocab_count += 1\n",
    "        print(\"初始化时间:\", time.time()-start_time)\n",
    "        start_time = time.time()\n",
    "        \n",
    "\n",
    "        # 开始byte pair合并操作\n",
    "        while vocab_count < vocab_size:\n",
    "            \n",
    "            \n",
    "            vocab_count += 1\n",
    "\n",
    "            max_count = max(counter_buffer.values())\n",
    "            \n",
    "            pairs = [pair for pair,count in counter_buffer.items() if count == max_count]\n",
    "            \n",
    "            merged_pair = pairs[0]\n",
    "            merge.append(merged_pair)\n",
    "            finalize_counter_buffer(\n",
    "                counter_buffer = counter_buffer,\n",
    "                merged_pair = merged_pair,\n",
    "                pair_trace = pair_trace,\n",
    "                single_token_buffer = single_token_buffer\n",
    "            )\n",
    "            counter[merged_pair] = max_count\n",
    "            vocab[merged_pair] = vocab_count\n",
    "            \n",
    "            for token in merged_pair:\n",
    "                counter[token] -= max_count\n",
    "                if counter[token] == 0:\n",
    "                    del vocab[token]\n",
    "                    vocab_count -= 1\n",
    "        print(\"循环耗时\", time.time()-start_time)\n",
    "        return merge, vocab\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1b50e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取数据时间: 0.04183340072631836\n",
      "初始化时间: 0.19279718399047852\n",
      "循环耗时 0.773115873336792\n",
      "1.0119178295135498\n"
     ]
    }
   ],
   "source": [
    "trainier = BPE_trainier()\n",
    "import time\n",
    "start_time = time.time()\n",
    "merge,vocab = trainier.train(file_path=\"tests/fixtures/corpus.en\",\n",
    "               vocab_size=500)\n",
    "\n",
    "\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26523071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{105: 0,\n",
       " 114: 1,\n",
       " 111: 2,\n",
       " 110: 3,\n",
       " 32: 4,\n",
       " 99: 5,\n",
       " 101: 6,\n",
       " 109: 7,\n",
       " 116: 8,\n",
       " 115: 9,\n",
       " 97: 10,\n",
       " 100: 11,\n",
       " 121: 12,\n",
       " 102: 13,\n",
       " 117: 14,\n",
       " 112: 15,\n",
       " 119: 16,\n",
       " 104: 17,\n",
       " 108: 18,\n",
       " 98: 19,\n",
       " 107: 20,\n",
       " 103: 21,\n",
       " 41: 23,\n",
       " 46: 24,\n",
       " 10: 25,\n",
       " 44: 26,\n",
       " 118: 27,\n",
       " 80: 28,\n",
       " 79: 29,\n",
       " 66: 30,\n",
       " 120: 31,\n",
       " 78: 32,\n",
       " 84: 33,\n",
       " 65: 34,\n",
       " 76: 35,\n",
       " 87: 36,\n",
       " 69: 37,\n",
       " 68: 38,\n",
       " 73: 39,\n",
       " 77: 40,\n",
       " 83: 41,\n",
       " 63: 43,\n",
       " 86: 44,\n",
       " 53: 45,\n",
       " 35: 46,\n",
       " 45: 48,\n",
       " 71: 49,\n",
       " 48: 50,\n",
       " 56: 51,\n",
       " 49: 52,\n",
       " 51: 53,\n",
       " 50: 54,\n",
       " 52: 55,\n",
       " 57: 56,\n",
       " 70: 57,\n",
       " 38: 58,\n",
       " 59: 59,\n",
       " 85: 60,\n",
       " 113: 61,\n",
       " 67: 62,\n",
       " 54: 63,\n",
       " 47: 64,\n",
       " 55: 65,\n",
       " 81: 66,\n",
       " 88: 67,\n",
       " 194: 68,\n",
       " 174: 69,\n",
       " 72: 70,\n",
       " 89: 71,\n",
       " 173: 72,\n",
       " 106: 73,\n",
       " 42: 74,\n",
       " 169: 76,\n",
       " 195: 77,\n",
       " 160: 78,\n",
       " 122: 79,\n",
       " 75: 81,\n",
       " 82: 82,\n",
       " 188: 83,\n",
       " 161: 84,\n",
       " 90: 85,\n",
       " 95: 86,\n",
       " 36: 87,\n",
       " 37: 88,\n",
       " 177: 89,\n",
       " 147: 90,\n",
       " 148: 91,\n",
       " 61: 92,\n",
       " 181: 93,\n",
       " 164: 94,\n",
       " 226: 95,\n",
       " 130: 96,\n",
       " 172: 97,\n",
       " 182: 98,\n",
       " 165: 99,\n",
       " 151: 100,\n",
       " 132: 101,\n",
       " 162: 102,\n",
       " 159: 103,\n",
       " 239: 104,\n",
       " 191: 105,\n",
       " 189: 106,\n",
       " 43: 107,\n",
       " '<|endoftext|>': 109,\n",
       " (32, 116): 110,\n",
       " (32, 97): 111,\n",
       " (104, 101): 112,\n",
       " (105, 110): 113,\n",
       " ((32, 116), 104): 114,\n",
       " (114, 101): 115,\n",
       " (32, 111): 116,\n",
       " (32, 44): 117,\n",
       " (101, 114): 118,\n",
       " (32, 115): 119,\n",
       " (97, 116): 120,\n",
       " (32, 46): 121,\n",
       " (110, 100): 122,\n",
       " (111, 114): 123,\n",
       " (105, 115): 124,\n",
       " (32, 119): 125,\n",
       " (111, 110): 126,\n",
       " (32, 99): 127,\n",
       " (32, 98): 128,\n",
       " (32, 102): 129,\n",
       " (101, 110): 130,\n",
       " (111, 117): 131,\n",
       " (105, 116): 132,\n",
       " (101, 115): 133,\n",
       " ((32, 97), 110): 134,\n",
       " ((32, 111), 102): 135,\n",
       " (32, 112): 136,\n",
       " (32, (105, 110)): 137,\n",
       " (101, 100): 138,\n",
       " (97, 108): 139,\n",
       " (32, 109): 140,\n",
       " (97, 110): 141,\n",
       " (32, 100): 142,\n",
       " ((105, 110), 103): 143,\n",
       " (97, 114): 144,\n",
       " ((32, 116), 111): 145,\n",
       " (111, 109): 146,\n",
       " (105, 99): 147,\n",
       " (108, 101): 148,\n",
       " (32, 104): 149,\n",
       " (108, 108): 150,\n",
       " (32, 121): 151,\n",
       " (115, 116): 152,\n",
       " (32, 101): 153,\n",
       " (115, 101): 154,\n",
       " (111, 116): 155,\n",
       " (116, 104): 156,\n",
       " (32, 108): 157,\n",
       " (32, 110): 158,\n",
       " (32, 117): 159,\n",
       " (97, 115): 160,\n",
       " (114, 111): 161,\n",
       " ((32, 98), 101): 162,\n",
       " (32, 38): 163,\n",
       " (118, 101): 164,\n",
       " (105, 108): 165,\n",
       " (32, (105, 115)): 166,\n",
       " (110, 116): 167,\n",
       " ((32, 121), (111, 117)): 168,\n",
       " (116, 101): 169,\n",
       " (32, (114, 101)): 170,\n",
       " (99, 101): 171,\n",
       " (117, 116): 172,\n",
       " ((32, 116), (104, 101)): 173,\n",
       " (116, 105): 174,\n",
       " (99, 104): 175,\n",
       " (105, 111): 176,\n",
       " ((32, 102), (111, 114)): 177,\n",
       " (111, 115): 178,\n",
       " (32, 103): 179,\n",
       " (97, 121): 180,\n",
       " (101, 116): 181,\n",
       " (97, 100): 182,\n",
       " (111, 119): 183,\n",
       " ((32, 111), 110): 184,\n",
       " (32, 73): 185,\n",
       " (109, 101): 186,\n",
       " (32, 65): 187,\n",
       " (((32, 116), 104), 97): 188,\n",
       " ((101, 110), 116): 189,\n",
       " (116, 115): 190,\n",
       " ((97, 116), 105): 191,\n",
       " ((32, 97), 114): 192,\n",
       " ((32, 104), 97): 193,\n",
       " (108, 121): 194,\n",
       " (113, 117): 195,\n",
       " (114, 105): 196,\n",
       " (97, 109): 197,\n",
       " ((104, 101), 114): 198,\n",
       " (105, 109): 199,\n",
       " (117, 114): 200,\n",
       " (118, (101, 114)): 201,\n",
       " (108, 100): 202,\n",
       " (32, 80): 203,\n",
       " (101, 108): 204,\n",
       " (32, 83): 205,\n",
       " (105, 114): 206,\n",
       " (32, (105, 116)): 207,\n",
       " (116, (104, 101)): 208,\n",
       " (115, 115): 209,\n",
       " (32, 67): 210,\n",
       " ((32, 115), 104): 211,\n",
       " (111, 108): 212,\n",
       " (32, 64): 213,\n",
       " ((32, 119), 104): 214,\n",
       " (110, 101): 215,\n",
       " (45, 64): 216,\n",
       " (97, 112): 216,\n",
       " (105, (111, 110)): 217,\n",
       " ((32, 64), 45): 218,\n",
       " ((32, 119), (105, 116)): 219,\n",
       " ((32, 99), (111, 109)): 220,\n",
       " (105, 100): 221,\n",
       " (99, 116): 222,\n",
       " ((111, 114), 100): 223,\n",
       " (116, 111): 224,\n",
       " (105, 102): 225,\n",
       " (101, 109): 226,\n",
       " (105, 103): 227,\n",
       " (104, 111): 228,\n",
       " (114, 97): 229,\n",
       " ((32, 97), 115): 230,\n",
       " ((101, 114), 115): 231,\n",
       " (32, (104, 101)): 232,\n",
       " ((114, 101), 115): 233,\n",
       " ((32, 97), 108): 234,\n",
       " (116, (101, 114)): 235,\n",
       " ((113, 117), (111, 116)): 236,\n",
       " (32, 77): 237,\n",
       " (97, 118): 238,\n",
       " (110, 103): 239,\n",
       " (97, 99): 240,\n",
       " ((97, 116), 101): 241,\n",
       " (97, (110, 100)): 242,\n",
       " (101, 101): 243,\n",
       " ((111, 117), 114): 244,\n",
       " (100, 101): 245,\n",
       " (32, 71): 246,\n",
       " ((105, 115), 116): 247,\n",
       " ((32, 111), 114): 248,\n",
       " (109, (101, 110)): 249,\n",
       " (105, 118): 250,\n",
       " (98, 108): 251,\n",
       " (111, 100): 252,\n",
       " (((32, 116), 104), 105): 253,\n",
       " (117, 115): 254,\n",
       " ((32, 119), 101): 255,\n",
       " ((32, 100), 101): 256,\n",
       " (105, 101): 257,\n",
       " (101, 121): 258,\n",
       " ((32, 117), 115): 259,\n",
       " (112, 101): 260,\n",
       " (103, 101): 261,\n",
       " (110, 115): 262,\n",
       " (32, 50): 263,\n",
       " ((32, 99), 97): 264,\n",
       " (32, 59): 265,\n",
       " ((32, 102), 114): 266,\n",
       " (32, 76): 267,\n",
       " ((32, 112), (114, 111)): 268,\n",
       " (117, 108): 269,\n",
       " (111, 111): 270,\n",
       " ((32, 99), (111, 110)): 271,\n",
       " ((97, 112), (111, 115)): 272,\n",
       " (112, 108): 273,\n",
       " (32, 40): 274,\n",
       " (107, 101): 274,\n",
       " ((32, 119), (111, 114)): 275,\n",
       " (48, 48): 276,\n",
       " (97, (105, 110)): 277,\n",
       " (32, 69): 278,\n",
       " ((32, 115), 116): 279,\n",
       " (97, 103): 280,\n",
       " ((32, 110), (111, 116)): 281,\n",
       " (32, 41): 282,\n",
       " (32, 49): 283,\n",
       " (117, 110): 284,\n",
       " (105, 97): 285,\n",
       " (101, (114, 101)): 286,\n",
       " (115, 105): 287,\n",
       " (116, 97): 288,\n",
       " (32, 68): 289,\n",
       " (99, (97, 116)): 290,\n",
       " ((32, 98), 121): 291,\n",
       " (104, (105, 99)): 292,\n",
       " (32, 118): 293,\n",
       " ((32, 110), 101): 294,\n",
       " ((32, 109), 97): 295,\n",
       " ((97, 114), 116): 296,\n",
       " ((32, 115), 101): 297,\n",
       " (108, 97): 298,\n",
       " (114, 115): 299,\n",
       " ((32, 121), 101): 300,\n",
       " (116, 121): 301,\n",
       " (32, 87): 302,\n",
       " ((114, 101), 110): 303,\n",
       " (111, 112): 304,\n",
       " (111, (114, 101)): 305,\n",
       " (32, 66): 306,\n",
       " (116, (105, 110)): 307,\n",
       " (103, 104): 308,\n",
       " (104, (97, 108)): 309,\n",
       " (32, 79): 310,\n",
       " (102, 101): 311,\n",
       " (32, 70): 312,\n",
       " (108, 111): 313,\n",
       " (32, 72): 314,\n",
       " ((32, 115), 117): 315,\n",
       " (100, (105, 110)): 316,\n",
       " ((32, 101), 118): 317,\n",
       " ((111, 114), 109): 318,\n",
       " (101, 97): 319,\n",
       " (97, 98): 320,\n",
       " (118, (101, 110)): 321,\n",
       " ((32, 108), 97): 322,\n",
       " ((32, 117), 112): 323,\n",
       " (111, 99): 324,\n",
       " ((32, 119), 105): 325,\n",
       " (115, (105, 110)): 326,\n",
       " ((101, 114), 121): 327,\n",
       " (117, 109): 328,\n",
       " (109, (101, 114)): 329,\n",
       " (117, 99): 330,\n",
       " ((32, 97), 99): 331,\n",
       " ((105, 116), 101): 332,\n",
       " ((32, 38), 35): 333,\n",
       " (104, 116): 334,\n",
       " ((97, 108), 108): 335,\n",
       " (46, 46): 336,\n",
       " (102, 116): 337,\n",
       " (97, (114, 101)): 338,\n",
       " ((111, 114), 107): 339,\n",
       " (32, 107): 340,\n",
       " (97, 107): 341,\n",
       " ((32, 101), 120): 342,\n",
       " ((32, 65), (110, 100)): 343,\n",
       " (100, 115): 344,\n",
       " (32, 84): 345,\n",
       " (50, 52): 346,\n",
       " ((32, 111), 117): 347,\n",
       " ((32, 46), 46): 348,\n",
       " ((105, 110), 101): 349,\n",
       " ((111, 114), 116): 350,\n",
       " (102, (111, 114)): 351,\n",
       " ((111, 117), 108): 352,\n",
       " ((111, 109), 109): 353,\n",
       " (108, 115): 354,\n",
       " ((32, 119), 97): 355,\n",
       " ((32, 109), 111): 356,\n",
       " (103, 115): 357,\n",
       " (99, (111, 109)): 358,\n",
       " ((32, 117), (110, 116)): 359,\n",
       " ((101, 114), 99): 360,\n",
       " ((32, 115), 97): 361,\n",
       " (115, 111): 362,\n",
       " (109, 115): 363,\n",
       " ((114, 101), 101): 364,\n",
       " (32, (108, 101)): 365,\n",
       " (49, (50, 52)): 366,\n",
       " ((32, 102), 105): 367,\n",
       " (((32, 99), (111, 109)), 112): 368,\n",
       " (112, 97): 369,\n",
       " (101, 99): 370,\n",
       " (114, 116): 371,\n",
       " ((101, 115), 115): 372,\n",
       " ((116, 104), (105, 115)): 373,\n",
       " (110, 99): 374,\n",
       " (114, 100): 375,\n",
       " (102, 111): 376,\n",
       " (114, 121): 377,\n",
       " (105, 122): 378,\n",
       " ((32, 97), 116): 379,\n",
       " ((32, 112), 108): 380,\n",
       " ((32, 109), 121): 381,\n",
       " (109, 97): 382,\n",
       " (110, 121): 383,\n",
       " (101, 119): 384,\n",
       " (112, 112): 385,\n",
       " ((32, 99), 104): 386,\n",
       " (112, (97, 114)): 387,\n",
       " ((105, 115), 104): 388,\n",
       " ((105, 116), 105): 389,\n",
       " (114, (111, 117)): 390,\n",
       " ((101, 115), 116): 391,\n",
       " (118, 105): 392,\n",
       " (108, (105, 110)): 393,\n",
       " ((32, 115), 111): 394,\n",
       " (112, (111, 114)): 395,\n",
       " ((32, 98), 117): 396,\n",
       " ((32, 115), (105, 116)): 397,\n",
       " (32, (118, (101, 114))): 398,\n",
       " (99, 97): 399,\n",
       " (117, 100): 400,\n",
       " ((105, 110), 100): 401,\n",
       " ((114, 101), 97): 402,\n",
       " (102, 102): 403,\n",
       " (117, (114, 101)): 404,\n",
       " (80, (114, 101)): 405,\n",
       " (112, (111, 110)): 406,\n",
       " (114, (97, 110)): 407,\n",
       " ((32, 110), 111): 408,\n",
       " (32, 106): 409,\n",
       " ((32, 97), 98): 410,\n",
       " (114, (105, 110)): 411,\n",
       " ((104, 101), 105): 412,\n",
       " ((97, 116), 97): 413,\n",
       " ((32, 109), 101): 414,\n",
       " ((32, 104), (105, 115)): 415,\n",
       " ((32, 116), 105): 416,\n",
       " (103, (105, 110)): 417,\n",
       " ((32, 119), (104, 101)): 418,\n",
       " (112, (101, 110)): 419,\n",
       " ((32, 50), (48, 48)): 420,\n",
       " (97, 105): 421,\n",
       " (104, 97): 422,\n",
       " (32, 45): 423,\n",
       " (32, 82): 424,\n",
       " (109, (97, 116)): 425,\n",
       " ((111, 110), 115): 426,\n",
       " (32, 78): 427,\n",
       " (100, 97): 428,\n",
       " (99, 105): 429,\n",
       " (108, 117): 430,\n",
       " (116, (97, 116)): 431,\n",
       " ((114, 101), (97, 116)): 432,\n",
       " ((111, 110), 97): 433,\n",
       " (32, (105, 109)): 434,\n",
       " (119, 97): 435,\n",
       " (32, 33): 436,\n",
       " (105, 98): 436,\n",
       " ((32, (105, 110)), 116): 437,\n",
       " ((32, 100), (97, 116)): 438,\n",
       " (97, (115, 116)): 439,\n",
       " ((115, 116), 101): 440,\n",
       " ((32, 101), 99): 441,\n",
       " (99, 108): 442,\n",
       " (117, 101): 443,\n",
       " (107, 115): 444,\n",
       " (67, 69): 445,\n",
       " ((32, 104), 111): 446,\n",
       " (99, (116, 105)): 447,\n",
       " (69, 99): 448,\n",
       " (((32, 116), 104), 111): 449,\n",
       " ((32, 109), (97, 110)): 450,\n",
       " ((32, 103), 111): 451,\n",
       " (32, (105, 102)): 452,\n",
       " ((105, 103), 104): 453,\n",
       " ((32, 73), (67, 69)): 454,\n",
       " (108, 105): 455,\n",
       " (99, 107): 456,\n",
       " (116, 109): 457,\n",
       " ((104, 101), 115): 458,\n",
       " (((32, 116), 104), (105, 110)): 459,\n",
       " (104, (111, 117)): 460,\n",
       " (99, (101, 115)): 461,\n",
       " (32, 54): 462,\n",
       " (32, 58): 463,\n",
       " (107, (105, 110)): 463,\n",
       " ((114, 101), 102): 464,\n",
       " ((101, 110), 115): 465,\n",
       " (101, (97, 114)): 466,\n",
       " (121, (115, 116)): 467,\n",
       " (101, 111): 468,\n",
       " (111, 107): 469,\n",
       " ((101, 114), 110): 470,\n",
       " (116, (111, 114)): 471,\n",
       " (108, (105, 115)): 472,\n",
       " ((32, 99), 111): 473,\n",
       " ((97, 110), 115): 474,\n",
       " ((32, 108), 111): 475,\n",
       " (111, 97): 476,\n",
       " ((105, 110), 115): 477,\n",
       " (114, (105, 115)): 478,\n",
       " ((32, 102), (114, 101)): 479,\n",
       " ((97, 114), 107): 480,\n",
       " (117, 103): 481,\n",
       " (110, (105, 110)): 482,\n",
       " (115, (101, 114)): 483,\n",
       " ((32, 99), (111, 117)): 484,\n",
       " ((32, 100), 111): 485,\n",
       " ((32, 83), 112): 486,\n",
       " ((105, 110), 99): 487,\n",
       " ((114, 101), 100): 488,\n",
       " ((104, 101), (114, 101)): 489,\n",
       " (98, (101, 114)): 490,\n",
       " ((32, 100), (111, 119)): 491,\n",
       " (114, 117): 492,\n",
       " (32, 74): 493,\n",
       " ((32, 111), 116): 493,\n",
       " ((32, 115), 121): 494,\n",
       " (114, (97, 116)): 495,\n",
       " (108, (97, 116)): 496,\n",
       " ((111, 110), 116): 497,\n",
       " (32, (101, 110)): 498,\n",
       " (117, (115, 116)): 499,\n",
       " ((32, 71), 111): 500}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "620a62ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [2,3,3,3]\n",
    "s.remove(3)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90937d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [3, 1], 'b': 3}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {\"a\":[3],\"b\":3}\n",
    "\n",
    "s = vocab.setdefault(\"a\")\n",
    "s.append(1)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5f91c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 1.5849e-01, 2.5119e-02, 3.9811e-03, 6.3096e-04, 1.0000e+00,\n",
      "         1.5849e-01, 2.5119e-02, 3.9811e-03, 6.3096e-04]], device='cuda:0')\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 1.5849e-01, 2.5119e-02, 3.9811e-03, 6.3096e-04, 1.0000e+00,\n",
      "         1.5849e-01, 2.5119e-02, 3.9811e-03, 6.3096e-04]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000],\n",
       "         [0.5403, 0.9875, 0.9997, 1.0000, 1.0000, 0.5403, 0.9875, 0.9997, 1.0000,\n",
       "          1.0000]], device='cuda:0'),\n",
       " tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [8.4147e-01, 1.5783e-01, 2.5116e-02, 3.9811e-03, 6.3096e-04, 8.4147e-01,\n",
       "          1.5783e-01, 2.5116e-02, 3.9811e-03, 6.3096e-04]], device='cuda:0'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "class DeepseekV2RotaryEmbedding(nn.Module):\n",
    "    def __init__(self, dim, max_position_embeddings=2048, base=10000, device=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.base = base\n",
    "        inv_freq = 1.0 / (\n",
    "            self.base ** (torch.arange(0, self.dim, 2).float().to(device) / self.dim)\n",
    "        )\n",
    "        self.register_buffer(\"inv_freq\", inv_freq, persistent=False)\n",
    "\n",
    "        # Build here to make `torch.jit.trace` work.\n",
    "        self._set_cos_sin_cache(\n",
    "            seq_len=max_position_embeddings,\n",
    "            device=self.inv_freq.device,\n",
    "            dtype=torch.get_default_dtype(),\n",
    "        )\n",
    "        self.max_seq_len_cached = None\n",
    "\n",
    "    def _set_cos_sin_cache(self, seq_len, device, dtype):\n",
    "        self.max_seq_len_cached = seq_len\n",
    "        \n",
    "        t = torch.arange(\n",
    "            self.max_seq_len_cached, device=device, dtype=self.inv_freq.dtype\n",
    "        )\n",
    "\n",
    "        freqs = torch.outer(t, self.inv_freq.to(t.device))\n",
    "        # Different from paper, but it uses a different permutation in order to obtain the same calculation\n",
    "        emb = torch.cat((freqs, freqs), dim=-1)\n",
    "        print(emb[:2,:])\n",
    "        self.register_buffer(\"cos_cached\", emb.cos().to(dtype), persistent=False)\n",
    "        self.register_buffer(\"sin_cached\", emb.sin().to(dtype), persistent=False)\n",
    "\n",
    "    def forward(self, x, seq_len=None):\n",
    "        # x: [bs, num_attention_heads, seq_len, head_size]\n",
    "        if self.max_seq_len_cached is None or seq_len > self.max_seq_len_cached:\n",
    "            self._set_cos_sin_cache(seq_len=seq_len, device=x.device, dtype=x.dtype)\n",
    "\n",
    "        return (\n",
    "            self.cos_cached[:seq_len].to(dtype=x.dtype),\n",
    "            self.sin_cached[:seq_len].to(dtype=x.dtype),\n",
    "        )\n",
    "model = DeepseekV2RotaryEmbedding(dim=10, device=\"cuda\")\n",
    "x = torch.randn((1,1,2,10), device=\"cuda\")\n",
    "model(x,seq_len = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
